# AR Jewelry Try-On Implementation Guide

## üéØ Overview

This implementation provides a professional-grade AR jewelry try-on system that matches Trillion Jewelry's functionality exactly. It uses MediaPipe for real-time face and hand tracking, with both 2D and 3D rendering capabilities.

## üèóÔ∏è Architecture

### Core Components

1. **`ARJewelryTryOn.tsx`** - Main AR component with full MediaPipe integration
2. **`OptimizedARJewelryTryOn.tsx`** - Performance-optimized version
3. **`MediaPipeManager.tsx`** - Centralized MediaPipe management
4. **`app/ar-demo/page.tsx`** - Demo page showcasing functionality

### Key Features

- ‚úÖ **Real-time Face Tracking** - MediaPipe FaceMesh for earrings and necklaces
- ‚úÖ **Hand Gesture Recognition** - MediaPipe Hands for ring positioning
- ‚úÖ **Selfie Segmentation** - Realistic jewelry placement behind hair/face
- ‚úÖ **2D & 3D Rendering** - Both image overlays and Three.js 3D models
- ‚úÖ **Performance Optimized** - 60fps real-time tracking
- ‚úÖ **Mobile & Desktop** - Cross-platform compatibility
- ‚úÖ **Natural Movement** - Jewelry follows face/hand rotation and scale

## üöÄ Quick Start

### 1. Install Dependencies

```bash
pnpm add @mediapipe/face_mesh @mediapipe/hands @mediapipe/selfie_segmentation @mediapipe/camera_utils @mediapipe/drawing_utils react-webcam three @react-three/fiber @react-three/drei
```

### 2. Basic Usage

```tsx
import OptimizedARJewelryTryOn from '@/components/OptimizedARJewelryTryOn';

const jewelryItems = [
  {
    id: 'diamond-earring',
    name: 'Diamond Stud Earrings',
    type: 'earring',
    imageUrl: 'https://example.com/earring.png',
    scale: 1,
    position: { x: 0, y: 0, z: 0 },
    rotation: { x: 0, y: 0, z: 0 }
  }
];

function MyARPage() {
  const [selectedJewelry, setSelectedJewelry] = useState(null);
  
  return (
    <OptimizedARJewelryTryOn
      jewelryItems={jewelryItems}
      onJewelrySelect={setSelectedJewelry}
      selectedJewelry={selectedJewelry}
      enable3D={false}
      className="w-full h-screen"
    />
  );
}
```

### 3. Demo Page

Visit `/ar-demo` to see the full implementation in action.

## üéØ AR Tracking Implementation

### Face Landmarks for Jewelry

```typescript
const JEWELRY_LANDMARKS = {
  // Ear positions for earrings
  LEFT_EAR: 234,
  RIGHT_EAR: 454,
  
  // Chin and jawline for necklaces
  CHIN: 152,
  JAW_LEFT: 172,
  JAW_RIGHT: 397,
  
  // Finger positions for rings
  INDEX_FINGER_TIP: 8,
  MIDDLE_FINGER_TIP: 12,
  RING_FINGER_TIP: 16,
  PINKY_TIP: 20,
  THUMB_TIP: 4
};
```

### Jewelry Positioning Logic

#### Earrings
- **Left Ear**: Uses landmark 234 for left earring
- **Right Ear**: Uses landmark 454 for right earring
- **Scaling**: 0.8x scale for natural appearance
- **Tracking**: Follows ear movement and rotation

#### Necklaces
- **Position**: Below chin using landmark 152
- **Curve**: Follows jawline using landmarks 172 and 397
- **Scaling**: 1.2x scale for proper fit
- **Tracking**: Moves with head rotation and tilt

#### Rings
- **Position**: Index finger tip using landmark 8
- **Hands**: Supports both left and right hands
- **Scaling**: 0.6x scale for finger fit
- **Tracking**: Follows finger movement and rotation

## üé® Rendering System

### 2D Rendering (Default)

```typescript
// Canvas-based rendering with transparency
const renderJewelry = useCallback(() => {
  const canvas = canvasRef.current;
  const ctx = canvas.getContext('2d');
  
  // Apply segmentation mask for realism
  if (segmentationMask) {
    ctx.putImageData(segmentationMask, 0, 0);
  }
  
  // Render jewelry with proper blending
  ctx.globalCompositeOperation = 'source-over';
  ctx.drawImage(jewelryImage, x, y, width, height);
}, [segmentationMask]);
```

### 3D Rendering (Optional)

```typescript
// Three.js integration for 3D models
<Canvas camera={{ position: [0, 0, 5] }}>
  <ambientLight intensity={0.5} />
  <directionalLight position={[10, 10, 5]} intensity={1} />
  
  {selectedJewelry && (
    <Jewelry3D
      jewelry={selectedJewelry}
      position={new THREE.Vector3(x, y, z)}
      rotation={new THREE.Euler(rx, ry, rz)}
      scale={scale}
    />
  )}
</Canvas>
```

## ‚ö° Performance Optimization

### MediaPipe Optimization

```typescript
// Optimized MediaPipe configuration
faceMesh.setOptions({
  maxNumFaces: 1,           // Single face for performance
  refineLandmarks: true,     // Higher accuracy
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
});

hands.setOptions({
  maxNumHands: 2,           // Both hands
  modelComplexity: 1,       // Balanced performance/accuracy
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
});
```

### Canvas Optimization

```typescript
// Efficient canvas rendering
const renderJewelry = useCallback(() => {
  // Only clear and redraw when necessary
  if (needsRedraw) {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    // Render jewelry...
  }
}, [needsRedraw]);
```

### Memory Management

```typescript
// Proper cleanup
useEffect(() => {
  return () => {
    stopTracking();
    faceMeshRef.current = null;
    handsRef.current = null;
    selfieSegmentationRef.current = null;
  };
}, []);
```

## üîß Configuration Options

### Jewelry Item Interface

```typescript
interface JewelryItem {
  id: string;                    // Unique identifier
  name: string;                  // Display name
  type: 'earring' | 'necklace' | 'ring';
  imageUrl?: string;             // 2D image URL
  modelUrl?: string;             // 3D model URL (GLTF/GLB)
  scale: number;                 // Base scale multiplier
  position: { x: number; y: number; z: number };
  rotation: { x: number; y: number; z: number };
}
```

### Component Props

```typescript
interface ARJewelryTryOnProps {
  jewelryItems: JewelryItem[];           // Available jewelry
  onJewelrySelect?: (jewelry: JewelryItem) => void;
  selectedJewelry?: JewelryItem | null;  // Currently selected
  enable3D?: boolean;                    // 3D rendering mode
  className?: string;                    // CSS classes
}
```

## üì± Mobile Compatibility

### Touch Controls

- **Tap to Select**: Touch jewelry buttons to select
- **Gesture Support**: Natural hand gestures for rings
- **Responsive Layout**: Adapts to mobile screen sizes

### Performance on Mobile

- **Optimized Models**: Lighter MediaPipe models for mobile
- **Battery Efficient**: Reduced processing when not tracking
- **Smooth Rendering**: 60fps on modern mobile devices

## üß™ Testing

### Automated Tests

```bash
# Run integration tests
npx playwright test tests/e2e/ar-tryon.spec.ts

# Run unit tests
npm test tests/unit/ar-components.test.ts
```

### Manual Testing

1. **Camera Permission**: Grant camera access when prompted
2. **Face Tracking**: Move face to test earring/necklace tracking
3. **Hand Tracking**: Show hands to test ring positioning
4. **Jewelry Selection**: Test all jewelry types
5. **Performance**: Verify smooth 60fps rendering

### Browser Console Testing

```javascript
// Run comprehensive tests
testARIntegration.runAllTests();

// Test specific functionality
testARIntegration.testCameraFunctionality();
testARIntegration.testJewelrySelection();
```

## üêõ Troubleshooting

### Common Issues

1. **Camera Not Working**
   - Check browser permissions
   - Ensure HTTPS in production
   - Verify camera availability

2. **MediaPipe Errors**
   - Check network connection
   - Verify CDN availability
   - Check browser compatibility

3. **Poor Performance**
   - Reduce jewelry image sizes
   - Lower MediaPipe confidence thresholds
   - Enable hardware acceleration

4. **Jewelry Not Positioning**
   - Ensure good lighting
   - Check face/hand visibility
   - Verify landmark detection

### Debug Mode

Enable debug mode to see tracking information:

```typescript
// Shows tracking status and landmark counts
{process.env.NODE_ENV === 'development' && (
  <div className="debug-info">
    <div>Status: {isTracking ? 'Tracking' : 'Not Tracking'}</div>
    <div>Face Landmarks: {faceLandmarks?.length || 0}</div>
    <div>Hand Landmarks: {handLandmarks.length}</div>
  </div>
)}
```

## üöÄ Production Deployment

### Environment Variables

```env
# Optional: Custom MediaPipe CDN
NEXT_PUBLIC_MEDIAPIPE_CDN=https://cdn.jsdelivr.net/npm/@mediapipe/

# Optional: Enable debug mode
NEXT_PUBLIC_AR_DEBUG=true
```

### Build Optimization

```javascript
// next.config.js
module.exports = {
  experimental: {
    optimizeCss: true,
    optimizePackageImports: ['@mediapipe/face_mesh', '@mediapipe/hands']
  }
};
```

### CDN Configuration

```javascript
// Custom MediaPipe CDN for better performance
const locateFile = (file) => {
  return `https://your-cdn.com/@mediapipe/face_mesh/${file}`;
};
```

## üìä Performance Metrics

### Target Performance

- **FPS**: 60fps on desktop, 30fps on mobile
- **Latency**: <100ms tracking delay
- **Memory**: <100MB RAM usage
- **CPU**: <30% CPU usage on modern devices

### Monitoring

```typescript
// Performance monitoring
const performanceMonitor = {
  startTime: performance.now(),
  frameCount: 0,
  
  measureFrame() {
    this.frameCount++;
    const now = performance.now();
    const fps = 1000 / (now - this.startTime);
    console.log(`FPS: ${fps.toFixed(2)}`);
    this.startTime = now;
  }
};
```

## üîÆ Future Enhancements

### Planned Features

1. **Advanced 3D Models**: GLTF/GLB support with animations
2. **Lighting System**: Dynamic lighting based on environment
3. **Physics Simulation**: Realistic jewelry movement
4. **Multi-User**: Support for multiple people in frame
5. **AI Enhancement**: Machine learning for better positioning

### Integration Possibilities

- **E-commerce**: Direct integration with product catalogs
- **Social Sharing**: AR filters for social media
- **Analytics**: User behavior tracking
- **Personalization**: AI-powered recommendations

## üìö References

- [MediaPipe Documentation](https://mediapipe.dev/)
- [Three.js Documentation](https://threejs.org/docs/)
- [React Three Fiber](https://docs.pmnd.rs/react-three-fiber)
- [WebRTC Camera API](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Implement your changes
4. Add tests
5. Submit a pull request

## üìÑ License

MIT License - see LICENSE file for details.
